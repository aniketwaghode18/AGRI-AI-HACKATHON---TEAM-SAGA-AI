import os
import csv
import json
import random
import shutil
from pathlib import Path
from typing import Dict, List, Tuple

try:
	import cv2
	_HAS_CV2 = True
except Exception:
	_HAS_CV2 = False

try:
	from PIL import Image
	_HAS_PIL = True
except Exception:
	_HAS_PIL = False


def read_annotations_csv(csv_path: Path) -> List[Dict]:
	"""Expected CSV header: filename,xmin,ymin,xmax,ymax,label"""
	records: List[Dict] = []
	with csv_path.open("r", newline="", encoding="utf-8") as f:
		reader = csv.DictReader(f)
		for row in reader:
			records.append({
				"filename": row["filename"],
				"xmin": int(float(row["xmin"])),
				"ymin": int(float(row["ymin"])),
				"xmax": int(float(row["xmax"])),
				"ymax": int(float(row["ymax"])),
				"label": str(row["label"]),
			})
	return records


def build_index(records: List[Dict]) -> Dict[str, List[Dict]]:
	index: Dict[str, List[Dict]] = {}
	for r in records:
		index.setdefault(r["filename"], []).append(r)
	return index


def compute_class_map(records: List[Dict]) -> Dict[str, int]:
	labels = sorted({r["label"] for r in records})
	return {lab: i for i, lab in enumerate(labels)}


def to_yolo_line(xmin: int, ymin: int, xmax: int, ymax: int, cls_id: int, img_w: int, img_h: int) -> str:
	"""Convert bbox to YOLO format: cls_id cx cy w h (normalized)"""
	w = xmax - xmin
	h = ymax - ymin
	cx = xmin + w / 2.0
	cy = ymin + h / 2.0
	return f"{cls_id} {cx/img_w:.6f} {cy/img_h:.6f} {w/img_w:.6f} {h/img_h:.6f}"


def resize_image_simple(img_path: Path, target_size: int) -> Tuple[int, int]:
	"""Resize image to fit within target_size, return (w, h)"""
	if not _HAS_PIL and not _HAS_CV2:
		return 640, 480  # fallback
	
	try:
		if _HAS_PIL:
			with Image.open(img_path) as im:
				w, h = im.size
				scale = min(target_size / w, target_size / h, 1.0)
				nw, nh = int(w * scale), int(h * scale)
				im_resized = im.resize((nw, nh), Image.Resampling.LANCZOS)
				im_resized.save(img_path, "JPEG", quality=95)
				return nw, nh
		elif _HAS_CV2:
			img = cv2.imread(str(img_path))
			h, w = img.shape[:2]
			scale = min(target_size / w, target_size / h, 1.0)
			nw, nh = int(w * scale), int(h * scale)
			img_resized = cv2.resize(img, (nw, nh))
			cv2.imwrite(str(img_path), img_resized, [cv2.IMWRITE_JPEG_QUALITY, 95])
			return nw, nh
	except Exception:
		pass
	return 640, 480


def convert_dataset_to_yolo_simple(
	images_dir: Path,
	annotations_csv: Path,
	out_dir: Path,
	splits: Tuple[float, float, float] = (0.8, 0.1, 0.1),
	img_size: int = 640,
	seed: int = 42,
) -> Dict:
	"""Convert to YOLO format without heavy dependencies."""
	out_dir.mkdir(parents=True, exist_ok=True)
	records = read_annotations_csv(annotations_csv)
	idx = build_index(records)
	class_map = compute_class_map(records)
	random.seed(seed)

	# Split by image
	all_images = sorted(idx.keys())
	random.shuffle(all_images)
	n = len(all_images)
	n_train = int(n * splits[0])
	n_val = int(n * splits[1])
	train_files = all_images[:n_train]
	val_files = all_images[n_train:n_train + n_val]
	test_files = all_images[n_train + n_val:]

	# Create dirs
	for split in ("train", "val", "test"):
		(out_dir / f"images/{split}").mkdir(parents=True, exist_ok=True)
		(out_dir / f"labels/{split}").mkdir(parents=True, exist_ok=True)

	def process_file(fname: str, split: str):
		src_path = images_dir / fname
		if not src_path.exists():
			return
		
		# Copy and resize image
		dst_img = out_dir / f"images/{split}" / fname
		shutil.copy2(src_path, dst_img)
		w, h = resize_image_simple(dst_img, img_size)
		
		# Write labels
		recs = idx.get(fname, [])
		label_path = out_dir / f"labels/{split}" / f"{Path(fname).stem}.txt"
		with label_path.open("w", encoding="utf-8") as lf:
			for r in recs:
				xmin = max(0, min(int(r["xmin"]), w - 1))
				ymin = max(0, min(int(r["ymin"]), h - 1))
				xmax = max(0, min(int(r["xmax"]), w - 1))
				ymax = max(0, min(int(r["ymax"]), h - 1))
				if xmax > xmin and ymax > ymin:
					cls_id = class_map[r["label"]]
					lf.write(to_yolo_line(xmin, ymin, xmax, ymax, cls_id, w, h) + "\n")

	# Process splits
	for fname in train_files:
		process_file(fname, "train")
	for fname in val_files:
		process_file(fname, "val")
	for fname in test_files:
		process_file(fname, "test")

	# Write data.yaml
	data_yaml = {
		"path": str(out_dir.as_posix()),
		"train": "images/train",
		"val": "images/val", 
		"test": "images/test",
		"names": {v: k for k, v in class_map.items()},
	}
	with (out_dir / "data.yaml").open("w", encoding="utf-8") as f:
		f.write("# Auto-generated by preprocess_simple.py\n")
		json_names_line = json.dumps(data_yaml["names"])
		f.write(f"path: {data_yaml['path']}\ntrain: {data_yaml['train']}\nval: {data_yaml['val']}\ntest: {data_yaml['test']}\nnames: {json_names_line}\n")

	stats = {
		"num_images": n,
		"split_counts": {"train": len(train_files), "val": len(val_files), "test": len(test_files)},
		"classes": {k: v for k, v in class_map.items()},
		"out_dir": str(out_dir),
	}
	return stats


def main():
	import argparse
	parser = argparse.ArgumentParser(description="Convert CSV-annotated dataset to YOLO format (simple, no augmentation).")
	parser.add_argument("--images_dir", type=str, required=True, help="Directory containing images.")
	parser.add_argument("--annotations_csv", type=str, required=True, help="CSV file with filename,xmin,ymin,xmax,ymax,label.")
	parser.add_argument("--out_dir", type=str, default="data/yolo_dataset", help="Output directory for YOLO dataset.")
	parser.add_argument("--splits", type=float, nargs=3, default=(0.8, 0.1, 0.1), help="Train/val/test split fractions.")
	parser.add_argument("--img_size", type=int, default=640, help="Target size for longest side.")
	parser.add_argument("--seed", type=int, default=42)
	args = parser.parse_args()

	stats = convert_dataset_to_yolo_simple(
		images_dir=Path(args.images_dir),
		annotations_csv=Path(args.annotations_csv),
		out_dir=Path(args.out_dir),
		splits=tuple(args.splits),
		img_size=args.img_size,
		seed=args.seed,
	)
	print(json.dumps(stats, indent=2))


if __name__ == "__main__":
	main()
